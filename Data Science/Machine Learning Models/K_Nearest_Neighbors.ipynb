{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## K-Nearest-Neighbors (KNN)\n",
    "The K-Nearest Neighbors algorithm uses the entire data set as the training set, rather than splitting the data set into a training set and test set.\n",
    "\n",
    "When an outcome is required for a new data instance, the KNN algorithm goes through the entire data set to find the k-nearest instances to the new instance, or the k number of instances most similar to the new record, and then outputs the mean of the outcomes (for a regression problem) or the mode (most frequent class) for a classification problem. The value of k is user-specified.\n",
    "\n",
    "The similarity between instances is calculated using measures such as Euclidean distance and Hamming distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![title](images/K-Nearest-Neighbors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# get data\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# split data into train(80%) & test(20%) data since we don't have anything to test on\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# initialize classifier\n",
    "k = 3 # number of neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# train/fit the model\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# use the model to predict the classes of the test data\n",
    "y_predict = knn.predict(x_test)\n",
    "\n",
    "# get the accuracy score\n",
    "metrics.accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GridSearchCV (Grid Search with Cross-Validation) - Trying Different Parameter Values \n",
    "Grid search is the process of performing hyper parameter tuning in order to determine the optimal values for a given model.\n",
    "\n",
    "The goal of cross-validation is to test the model's ability to predict new data that was not used in estimating it, in order to flag problems like overfitting or selection bias and to give an insight on how the model will generalize to an independent dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K-Neighbors ==> {'n_neighbors': 13}\n",
      "Mean Score = 0.9800000000000001\n",
      "Accuracy Score = 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1, 25)\n",
    "}\n",
    "\n",
    "# use gridsearch to test a range of values for n_neightbors\n",
    "# cv is preferable to be 10 as most of the time this value gives good results\n",
    "# cv = 10 means that x_train is splitted into 10 groups where 9 are for training and 1 is for testing\n",
    "# these groups shuffle to search for the best train data for the model\n",
    "knn = KNeighborsClassifier()\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=10)\n",
    "\n",
    "# fit model to data\n",
    "knn_gscv.fit(x, y)\n",
    "\n",
    "# predict\n",
    "y_predict_gscv = knn_gscv.predict(x_test)\n",
    "\n",
    "# check the best n-neighbors value\n",
    "print(f'Best K-Neighbors ==> {knn_gscv.best_params_}')\n",
    "\n",
    "# mean best score\n",
    "print(f'Mean Score = {knn_gscv.best_score_}')\n",
    "\n",
    "# Accuracy score\n",
    "print(f'Accuracy Score = {metrics.accuracy_score(y_test, y_predict_gscv)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
