In a nutshell:
--------------
1 - input layer -> hidden layers -> output layer.
2 - consists of nodes.
3 - each node is connected to other nodes with a weight value.
4 - each input node is connected to all middle layer nodes.
5 - each node has a value(activation) gotten from the sum of all ((activation * weight) + bias) from all
connected nodes to it.
6 - bias is the value added when calculating the current node activation.
7 - each activation result in any layer is the input for the next layer.
8 - after each output from output layer there is a cost function that calculate how much the current prediction
deviates from the previous one so that we can update the wieghts and biases according to it.
9 - training means to minimize the value of the cost (error) function to get the best prediction
that is near or equal to our desired output.

Keywords:
---------
1 - input nodes - hidden nodes - output nodes
2 - bias & weight
3 - activation function (sigmoid, softmax, relu, ...etc)
4 - loss/cost/error function (squared error, sparse_categorical_crossentropy, ...etc)
5 - optimizers (GB, SGB, Adam, ...etc)
6 - learning rate for optimizers
7 - layers (Convolutional, Dense, ...etc)
8 - models:
        - object detection:
        -------------------
            YOLO, tiny-YOLO, SSD, RCNN, Fast-RCNN, Faster-RCNN, Mask_RCNN, ...etc
        
        - text:
        -------
            LSTM, NLP, ...etc

